{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pandas.set_option('display.max_colwidth', 200)\n",
    "np.random.seed(127205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "def cleanup(tweets):\n",
    "    tweets = tweets.dropna()\n",
    "    tweets = tweets.drop(columns=['Id'])\n",
    "    tweets = tweets[tweets.Category != 'Tweet']\n",
    "    tweets = tweets[tweets.Tweet != 'Not Available']\n",
    "    tweets = tweets[tweets.Tweet != '']\n",
    "    return tweets\n",
    "\n",
    "import re\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stops = {'in', 'of', 'at', 'a', 'the', 'to', 'on', 'and', 'it'}\n",
    "stops.update(string.punctuation)\n",
    "stops.difference_update('?!')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tag_for_lemmatizer(tag):\n",
    "    if tag.startswith('NN'):\n",
    "        return 'n'\n",
    "    if tag.startswith('VB'):\n",
    "        return 'v'\n",
    "    return 'a'\n",
    "\n",
    "def preprocess(text, lemmatize=True):\n",
    "    if not text or type(text) != str:\n",
    "        return ''\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://[^\\s]+\", '', text) # hyperlinks\n",
    "    text = re.sub(r\"\\@\\w+\", '', text) # mentions\n",
    "    text = re.sub(r\"#\", '', text) # hashtags\n",
    "    text = re.sub(r\"\\d+\\w*\", '', text) # numbers\n",
    "    text = re.sub(r\"'s\", '', text) # possesive\n",
    "    text = re.sub(r\"n't\", ' not', text) # contractions\n",
    "    text = re.sub(r\"'m\", ' am', text)\n",
    "    text = re.sub(r\"'s\", ' is', text)\n",
    "    text = re.sub(r\"'re\", ' are', text)\n",
    "    \n",
    "    words = [word for word in casual_tokenize(text) if word not in stops]\n",
    "    \n",
    "    if lemmatize:\n",
    "        words = [\n",
    "            lemmatizer.lemmatize(word, tag_for_lemmatizer(tag))\n",
    "            for word, tag in pos_tag(words)\n",
    "        ]\n",
    "    else:\n",
    "        words = [\n",
    "            stemmer.stem(word)\n",
    "            for word in words\n",
    "        ]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>io app transport security mm need check if my party network pod support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mar if you have an ios device you should download our app too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>my phone do not run late io which may account for problem other day .. time be replace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>not sure how start your publication io ? we'll be live help with ask me anything session today friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two dollar tuesday be here with forklift quickkey for io suite for page for just today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>positive</td>\n",
       "      <td>ok ed let do this zlatan greizmann laporte tomorrow make happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>neutral</td>\n",
       "      <td>goal level zlatan by friday ? post every other day dsgs vine by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>neutral</td>\n",
       "      <td>would not surprise me if we enquired.he ca not be happy play fiddle zlatan but he not worth psg ask price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rib injury for zlatan against russia be big blow if he miss austria game tuesday chance for new sunderland striker toivonen safc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>neutral</td>\n",
       "      <td>noooooo ! i be hop see zlatan be zlatan tuesday ! oh well still look forward match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5421 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  \\\n",
       "1      neutral   \n",
       "2      neutral   \n",
       "3     negative   \n",
       "4     positive   \n",
       "5      neutral   \n",
       "...        ...   \n",
       "5963  positive   \n",
       "5964   neutral   \n",
       "5965   neutral   \n",
       "5966   neutral   \n",
       "5967   neutral   \n",
       "\n",
       "                                                                                                                                 Tweet  \n",
       "1                                                              io app transport security mm need check if my party network pod support  \n",
       "2                                                                        mar if you have an ios device you should download our app too  \n",
       "3                                               my phone do not run late io which may account for problem other day .. time be replace  \n",
       "4                                not sure how start your publication io ? we'll be live help with ask me anything session today friday  \n",
       "5                                               two dollar tuesday be here with forklift quickkey for io suite for page for just today  \n",
       "...                                                                                                                                ...  \n",
       "5963                                                                   ok ed let do this zlatan greizmann laporte tomorrow make happen  \n",
       "5964                                                                   goal level zlatan by friday ? post every other day dsgs vine by  \n",
       "5965                         would not surprise me if we enquired.he ca not be happy play fiddle zlatan but he not worth psg ask price  \n",
       "5966  rib injury for zlatan against russia be big blow if he miss austria game tuesday chance for new sunderland striker toivonen safc  \n",
       "5967                                                noooooo ! i be hop see zlatan be zlatan tuesday ! oh well still look forward match  \n",
       "\n",
       "[5421 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train set\n",
    "\n",
    "tweets = pandas.read_csv('data/train.csv')\n",
    "tweets = cleanup(tweets)\n",
    "tweets.Tweet = tweets.Tweet.apply(preprocess, lemmatize=True)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# convert text to sequences\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweets.Tweet)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(tweets.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  905, 4080,  284],\n",
       "       [   0,    0,    0, ...,  122,  420,  210],\n",
       "       [   0,    0,    0, ...,   24,    1,  906],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  648,  289,  756],\n",
       "       [   0,    0,    0, ..., 1017, 9219, 9220],\n",
       "       [   0,    0,    0, ...,   65,  463,  334]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]\n",
    "plt.hist(lengths)\n",
    "plt.show()\n",
    "\n",
    "max_words = 30\n",
    "sequences = sequence.pad_sequences(sequences, maxlen=max_words)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categories to one-hot vectors\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = ohe.fit_transform(tweets.Category.values.reshape(-1, 1))\n",
    "num_classes = len(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, y, test_size=0.2)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Google word2vec embeddings\n",
    "\n",
    "import gensim\n",
    "\n",
    "# download it from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "word2vec_file = 'models/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "embedding_weights = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_weights[idx, :] = word2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 300)           2766600   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 2,927,303\n",
      "Trainable params: 160,703\n",
      "Non-trainable params: 2,766,600\n",
      "_________________________________________________________________\n",
      "Train on 3468 samples, validate on 868 samples\n",
      "Epoch 1/6\n",
      "3468/3468 [==============================] - 4s 1ms/step - loss: 1.0072 - accuracy: 0.4801 - val_loss: 0.9591 - val_accuracy: 0.5242\n",
      "Epoch 2/6\n",
      "3468/3468 [==============================] - 3s 925us/step - loss: 0.9640 - accuracy: 0.5291 - val_loss: 0.9229 - val_accuracy: 0.5334\n",
      "Epoch 3/6\n",
      "3468/3468 [==============================] - 3s 961us/step - loss: 0.9469 - accuracy: 0.5234 - val_loss: 0.9070 - val_accuracy: 0.5714\n",
      "Epoch 4/6\n",
      "3468/3468 [==============================] - 3s 923us/step - loss: 0.9345 - accuracy: 0.5467 - val_loss: 0.8998 - val_accuracy: 0.5472\n",
      "Epoch 5/6\n",
      "3468/3468 [==============================] - 3s 919us/step - loss: 0.9165 - accuracy: 0.5510 - val_loss: 0.9388 - val_accuracy: 0.5150\n",
      "Epoch 6/6\n",
      "3468/3468 [==============================] - 3s 916us/step - loss: 0.9271 - accuracy: 0.5482 - val_loss: 0.9080 - val_accuracy: 0.5346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26b734eb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup and train neural network\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "\n",
    "def create_model(embedding_weights, num_classes, spatial_dropout=0.5, lstm_dropout=0.5, recurrent_dropout=0.5):\n",
    "    vocab_size, embedding_dim = embedding_weights.shape\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_words, weights=[embedding_weights], trainable=False),\n",
    "        SpatialDropout1D(spatial_dropout),\n",
    "        LSTM(100, dropout=lstm_dropout, recurrent_dropout=recurrent_dropout),\n",
    "        Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(embedding_weights, num_classes)\n",
    "model.summary()\n",
    "\n",
    "epochs = 6\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9  81  94]\n",
      " [  3 122 257]\n",
      " [  0  36 483]]\n",
      "0.5658986175115207\n"
     ]
    }
   ],
   "source": [
    "# check against the test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "predictions = model.predict_classes(x_test)\n",
    "truth = y_test.argmax(1)\n",
    "\n",
    "print(confusion_matrix(truth, predictions))\n",
    "print(accuracy_score(truth, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.16666666666666666, 0.16666666666666666, 0.16666666666666666) 0.5981566820276498\n",
      "(0.16666666666666666, 0.16666666666666666, 0.3333333333333333) 0.6055299539170507\n",
      "(0.16666666666666666, 0.16666666666666666, 0.5) 0.6082949308755761\n",
      "(0.16666666666666666, 0.3333333333333333, 0.16666666666666666) 0.6\n",
      "(0.16666666666666666, 0.3333333333333333, 0.3333333333333333) 0.5926267281105991\n",
      "(0.16666666666666666, 0.3333333333333333, 0.5) 0.5935483870967742\n",
      "(0.16666666666666666, 0.5, 0.16666666666666666) 0.5963133640552996\n",
      "(0.16666666666666666, 0.5, 0.3333333333333333) 0.5972350230414747\n",
      "(0.16666666666666666, 0.5, 0.5) 0.5907834101382489\n",
      "(0.3333333333333333, 0.16666666666666666, 0.16666666666666666) 0.5880184331797235\n",
      "(0.3333333333333333, 0.16666666666666666, 0.3333333333333333) 0.6092165898617512\n",
      "(0.3333333333333333, 0.16666666666666666, 0.5) 0.5935483870967742\n",
      "(0.3333333333333333, 0.3333333333333333, 0.16666666666666666) 0.6064516129032258\n",
      "(0.3333333333333333, 0.3333333333333333, 0.3333333333333333) 0.6092165898617512\n",
      "(0.3333333333333333, 0.3333333333333333, 0.5) 0.5963133640552996\n",
      "(0.3333333333333333, 0.5, 0.16666666666666666) 0.584331797235023\n",
      "(0.3333333333333333, 0.5, 0.3333333333333333) 0.5926267281105991\n",
      "(0.3333333333333333, 0.5, 0.5) 0.5972350230414747\n",
      "(0.5, 0.16666666666666666, 0.16666666666666666) 0.5990783410138248\n",
      "(0.5, 0.16666666666666666, 0.3333333333333333) 0.5935483870967742\n",
      "(0.5, 0.16666666666666666, 0.5) 0.5990783410138248\n",
      "(0.5, 0.3333333333333333, 0.16666666666666666) 0.5870967741935483\n",
      "(0.5, 0.3333333333333333, 0.3333333333333333) 0.5622119815668203\n",
      "(0.5, 0.3333333333333333, 0.5) 0.5880184331797235\n",
      "(0.5, 0.5, 0.16666666666666666) 0.567741935483871\n",
      "(0.5, 0.5, 0.3333333333333333) 0.5806451612903226\n",
      "(0.5, 0.5, 0.5) 0.576036866359447\n"
     ]
    }
   ],
   "source": [
    "# optimize dropout hyperparameters\n",
    "\n",
    "import itertools\n",
    "\n",
    "values = np.arange(1, 4) / 6\n",
    "scores = {}\n",
    "\n",
    "for params in itertools.product(values, repeat=3):\n",
    "    model = create_model(embedding_weights, num_classes, *params)\n",
    "    model.fit(x_train, y_train,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    accuracy = accuracy_score(truth, model.predict_classes(x_test))\n",
    "    print(params, accuracy)\n",
    "    scores[params] = accuracy\n",
    "\n",
    "best_params = max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.16666666666666666, 0.3333333333333333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "5421/5421 [==============================] - 5s 935us/step - loss: 0.9610 - accuracy: 0.5185\n",
      "Epoch 2/6\n",
      "5421/5421 [==============================] - 5s 857us/step - loss: 0.8962 - accuracy: 0.5632\n",
      "Epoch 3/6\n",
      "5421/5421 [==============================] - 5s 847us/step - loss: 0.8764 - accuracy: 0.5805\n",
      "Epoch 4/6\n",
      "5421/5421 [==============================] - 5s 849us/step - loss: 0.8614 - accuracy: 0.5888\n",
      "Epoch 5/6\n",
      "5421/5421 [==============================] - 5s 888us/step - loss: 0.8461 - accuracy: 0.6003\n",
      "Epoch 6/6\n",
      "5421/5421 [==============================] - 5s 869us/step - loss: 0.8404 - accuracy: 0.6008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21fed2a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on entire set with best params\n",
    "\n",
    "model = create_model(embedding_weights, num_classes, *best_params)\n",
    "model.fit(sequences, y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I loved it!': 'positive',\n",
       " \"I don't know what to say\": 'neutral',\n",
       " 'What a fucking piece of shit!': 'negative'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on our own input\n",
    "\n",
    "def classify(text):\n",
    "    text = preprocess(text)\n",
    "    test_seq = tokenizer.texts_to_sequences([text])\n",
    "    test_seq = sequence.pad_sequences(test_seq, maxlen=max_words)\n",
    "    predictions = model.predict_classes(test_seq)\n",
    "    return ohe.categories_[0][predictions[0]]\n",
    "\n",
    "phrases = [\"I loved it!\", \"I don't know what to say\", \"What a fucking piece of shit!\"]\n",
    "{ phrase: classify(phrase) for phrase in phrases }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict categories on the external test set\n",
    "\n",
    "def classify_array(texts):\n",
    "    texts = [preprocess(text) for text in texts]\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    sequences = sequence.pad_sequences(sequences, maxlen=max_words)\n",
    "    predictions = model.predict_classes(sequences)\n",
    "    return ohe.categories_[0][predictions]\n",
    "\n",
    "test_tweets = pandas.read_csv('data/test.csv', dtype={'Id': str, 'Tweet': str})\n",
    "test_tweets['Category'] = classify_array(test_tweets.Tweet)\n",
    "\n",
    "with open('predictions.csv', 'wt') as f:\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for i, row in test_tweets.iterrows():\n",
    "        f.write(f\"{row.Id},{row.Category}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>Two top Senate investigators offered potential immunity Tuesday to Bryan Pagliano, the staffer who set up the email server in HILLARY</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Got the new PC up and running! Batman looks GLORIOUS!! We'll be casting it tomorrow! See you at 11am PST!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>Finally it's Sunday Funday!   Whether you were out seeing Tim McGraw or watching Conor McGregor win the fight... http://t.co/83pta9TIDA</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>someone wanna watch the sun rise and go to IHOP?</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>my life consists of taking care of Bentley and waiting for Under the Dome every thurs.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>'Angela Merkel' stars in lesbian magazine ad: Wednesday sees the launch of new magazine \"Straight,\" aimed at g... http://t.co/7hUcJ0F0qI</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>@ianbremmer @Eagle_Vision I'm sure Hillary kept a copy of all the original emails somewhere. Where is the 5th thumb-drive Hillary?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>This may have changed my mind about buying an Apple Watch.  http://t.co/7uCLCt0ydK</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>I really expected an Apple Watch to be a bit smarter than just telling me to stand up after I just sat down, only because it's 4:50pm.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Mobile News AppYea Prepping New Mobile App for Apple Watch - On Tuesday morning, MMW was briefed by the crew at Ap... http://t.co/SA5Cl5CGvg</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>Disappointing end to the match for Isner. Would've liked to see a 3rd set tiebreak but Federer is a robot. He's ridiculous.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>And the new Bentley truck is officially coming out  https://t.co/C4u0Vr9Aon</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Did you get a chance to join our Google+ Hangout Friday, July 24th? Take a few minutes to watch the live broadcast! http://t.co/AcGBNlDnGi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>Wow, just wow! David Cameron must have experienced a lucid moment.  https://t.co/ahVfbLhgAQ</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>@Sams_Nice_Car -smoothed out. If it was up to Bentley, the sun-speckled skin would be perfect for a photoshoot. Still, Dodger is Dodger, -</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>Tennis-Tough tests from the start for Federer, Murray: NEW YORK, Aug 30 (Reuters) - Roger Federer and Andy Mur... http://t.co/tTA6zJvQDr</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>Holy shit I just now opened the Hannibal's Kitchen envelope someone handed me Friday night #dragoncon #Hannibal http://t.co/v8DX9Jl0Pv</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>I should've just shared it on Google+ :/ But this was what never reached you Friday night, @JoshuaDtown. Congrats!!! http://t.co/lMJGRpWOe5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             Tweet  \\\n",
       "3792         Two top Senate investigators offered potential immunity Tuesday to Bryan Pagliano, the staffer who set up the email server in HILLARY   \n",
       "1076                                     Got the new PC up and running! Batman looks GLORIOUS!! We'll be casting it tomorrow! See you at 11am PST!   \n",
       "1925       Finally it's Sunday Funday!   Whether you were out seeing Tim McGraw or watching Conor McGregor win the fight... http://t.co/83pta9TIDA   \n",
       "3949                                                                                              someone wanna watch the sun rise and go to IHOP?   \n",
       "1273                                                        my life consists of taking care of Bentley and waiting for Under the Dome every thurs.   \n",
       "529       'Angela Merkel' stars in lesbian magazine ad: Wednesday sees the launch of new magazine \"Straight,\" aimed at g... http://t.co/7hUcJ0F0qI   \n",
       "3750            @ianbremmer @Eagle_Vision I'm sure Hillary kept a copy of all the original emails somewhere. Where is the 5th thumb-drive Hillary?   \n",
       "757                                                             This may have changed my mind about buying an Apple Watch.  http://t.co/7uCLCt0ydK   \n",
       "762         I really expected an Apple Watch to be a bit smarter than just telling me to stand up after I just sat down, only because it's 4:50pm.   \n",
       "735   Mobile News AppYea Prepping New Mobile App for Apple Watch - On Tuesday morning, MMW was briefed by the crew at Ap... http://t.co/SA5Cl5CGvg   \n",
       "2792                   Disappointing end to the match for Isner. Would've liked to see a 3rd set tiebreak but Federer is a robot. He's ridiculous.   \n",
       "1206                                                                   And the new Bentley truck is officially coming out  https://t.co/C4u0Vr9Aon   \n",
       "3938                                                                                                                                 Not Available   \n",
       "3247    Did you get a chance to join our Google+ Hangout Friday, July 24th? Take a few minutes to watch the live broadcast! http://t.co/AcGBNlDnGi   \n",
       "2148                                                   Wow, just wow! David Cameron must have experienced a lucid moment.  https://t.co/ahVfbLhgAQ   \n",
       "1210    @Sams_Nice_Car -smoothed out. If it was up to Bentley, the sun-speckled skin would be perfect for a photoshoot. Still, Dodger is Dodger, -   \n",
       "2738      Tennis-Tough tests from the start for Federer, Murray: NEW YORK, Aug 30 (Reuters) - Roger Federer and Andy Mur... http://t.co/tTA6zJvQDr   \n",
       "519                                                                                                                                  Not Available   \n",
       "3481        Holy shit I just now opened the Hannibal's Kitchen envelope someone handed me Friday night #dragoncon #Hannibal http://t.co/v8DX9Jl0Pv   \n",
       "3207   I should've just shared it on Google+ :/ But this was what never reached you Friday night, @JoshuaDtown. Congrats!!! http://t.co/lMJGRpWOe5   \n",
       "\n",
       "      Category  \n",
       "3792   neutral  \n",
       "1076  positive  \n",
       "1925  positive  \n",
       "3949  positive  \n",
       "1273  positive  \n",
       "529   positive  \n",
       "3750   neutral  \n",
       "757   positive  \n",
       "762    neutral  \n",
       "735   positive  \n",
       "2792  positive  \n",
       "1206  positive  \n",
       "3938  positive  \n",
       "3247  positive  \n",
       "2148  positive  \n",
       "1210  positive  \n",
       "2738   neutral  \n",
       "519   positive  \n",
       "3481  positive  \n",
       "3207  positive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets[['Tweet', 'Category']].sample(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
