{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pandas.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check if my 3rd party network pod supports it http://t.co/fmtcfUAdgj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should download our app too: http://t.co/gl3tn2uDnD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday http://t.co/KPqqGjjh3x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>639016598477651968</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@YouAreMyArsenal Wouldn't surprise me if we enquired.He can't be 100% happy playing 2nd fiddle to Zlatan but he's not worth PSG asking price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>640276909633486849</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Rib injury for Zlatan against Russia is a big blow if he misses Austria game Tuesday. A chance for new Sunderland striker Toivonen #SAFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>640296841725235200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Noooooo! I was hoping to see Zlatan being Zlatan in Tuesday! Oh well, still looking forward to the match.  https://t.co/swGyd9cQAJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>641017384908779520</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>641395811474128896</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5970 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Id  Category  \\\n",
       "0     635769805279248384  negative   \n",
       "1     635930169241374720   neutral   \n",
       "2     635950258682523648   neutral   \n",
       "3     636030803433009153  negative   \n",
       "4     636100906224848896  positive   \n",
       "...                  ...       ...   \n",
       "5965  639016598477651968   neutral   \n",
       "5966  640276909633486849   neutral   \n",
       "5967  640296841725235200   neutral   \n",
       "5968  641017384908779520   neutral   \n",
       "5969  641395811474128896   neutral   \n",
       "\n",
       "                                                                                                                                             Tweet  \n",
       "0                                                                                                                                    Not Available  \n",
       "1                                    IOS 9 App Transport Security. Mm need to check if my 3rd party network pod supports it http://t.co/fmtcfUAdgj  \n",
       "2                                                           Mar if you have an iOS device, you should download our app too: http://t.co/gl3tn2uDnD  \n",
       "3                          @jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced  \n",
       "4       Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday http://t.co/KPqqGjjh3x  \n",
       "...                                                                                                                                            ...  \n",
       "5965  @YouAreMyArsenal Wouldn't surprise me if we enquired.He can't be 100% happy playing 2nd fiddle to Zlatan but he's not worth PSG asking price  \n",
       "5966      Rib injury for Zlatan against Russia is a big blow if he misses Austria game Tuesday. A chance for new Sunderland striker Toivonen #SAFC  \n",
       "5967            Noooooo! I was hoping to see Zlatan being Zlatan in Tuesday! Oh well, still looking forward to the match.  https://t.co/swGyd9cQAJ  \n",
       "5968                                                                                                                                 Not Available  \n",
       "5969                                                                                                                                 Not Available  \n",
       "\n",
       "[5970 rows x 3 columns]"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.483752\n",
       "neutral     0.355946\n",
       "negative    0.160134\n",
       "Tweet       0.000168\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.Category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(tweets):\n",
    "    tweets = tweets.dropna()\n",
    "    tweets = tweets.drop(columns=['Id'])\n",
    "    tweets = tweets[tweets.Category != 'Tweet']\n",
    "    tweets = tweets[tweets.Tweet != 'Not Available']\n",
    "    tweets = tweets[tweets.Tweet != '']\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check if my 3rd party network pod supports it http://t.co/fmtcfUAdgj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should download our app too: http://t.co/gl3tn2uDnD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday http://t.co/KPqqGjjh3x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Two Dollar Tuesday is here with Forklift 2, QuickKey for iOS and Suite for Pages for just $1.99 today:   http://t.co/BNMFOEACw5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>positive</td>\n",
       "      <td>Ok ed let's do this, Zlatan, greizmann and Laporte tomorrow make it happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Goal level: Zlatan  90k by Friday? = Posting every other day  #DSGS (Vine by @ElexAuerbach) https://t.co/BPUM3A8tSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@YouAreMyArsenal Wouldn't surprise me if we enquired.He can't be 100% happy playing 2nd fiddle to Zlatan but he's not worth PSG asking price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rib injury for Zlatan against Russia is a big blow if he misses Austria game Tuesday. A chance for new Sunderland striker Toivonen #SAFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Noooooo! I was hoping to see Zlatan being Zlatan in Tuesday! Oh well, still looking forward to the match.  https://t.co/swGyd9cQAJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5421 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  \\\n",
       "1      neutral   \n",
       "2      neutral   \n",
       "3     negative   \n",
       "4     positive   \n",
       "5      neutral   \n",
       "...        ...   \n",
       "5963  positive   \n",
       "5964   neutral   \n",
       "5965   neutral   \n",
       "5966   neutral   \n",
       "5967   neutral   \n",
       "\n",
       "                                                                                                                                             Tweet  \n",
       "1                                    IOS 9 App Transport Security. Mm need to check if my 3rd party network pod supports it http://t.co/fmtcfUAdgj  \n",
       "2                                                           Mar if you have an iOS device, you should download our app too: http://t.co/gl3tn2uDnD  \n",
       "3                          @jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced  \n",
       "4       Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday http://t.co/KPqqGjjh3x  \n",
       "5                  Two Dollar Tuesday is here with Forklift 2, QuickKey for iOS and Suite for Pages for just $1.99 today:   http://t.co/BNMFOEACw5  \n",
       "...                                                                                                                                            ...  \n",
       "5963                                                                    Ok ed let's do this, Zlatan, greizmann and Laporte tomorrow make it happen  \n",
       "5964                           Goal level: Zlatan  90k by Friday? = Posting every other day  #DSGS (Vine by @ElexAuerbach) https://t.co/BPUM3A8tSD  \n",
       "5965  @YouAreMyArsenal Wouldn't surprise me if we enquired.He can't be 100% happy playing 2nd fiddle to Zlatan but he's not worth PSG asking price  \n",
       "5966      Rib injury for Zlatan against Russia is a big blow if he misses Austria game Tuesday. A chance for new Sunderland striker Toivonen #SAFC  \n",
       "5967            Noooooo! I was hoping to see Zlatan being Zlatan in Tuesday! Oh well, still looking forward to the match.  https://t.co/swGyd9cQAJ  \n",
       "\n",
       "[5421 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = cleanup(tweets)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.479432\n",
       "neutral     0.360266\n",
       "negative    0.160303\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tweets.Category.unique()\n",
    "tweets.Category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stops = {'in', 'of', 'at', 'a', 'the', 'to', 'on', 'and', 'it'}\n",
    "stops.update(string.punctuation)\n",
    "stops.difference_update('?!')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tag_for_lemmatizer(tag):\n",
    "    if tag.startswith('NN'):\n",
    "        return 'n'\n",
    "    if tag.startswith('VB'):\n",
    "        return 'v'\n",
    "    return 'a'\n",
    "\n",
    "def preprocess(text, lemmatize=True):\n",
    "    if not text or type(text) != str:\n",
    "        return ''\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://[^\\s]+\", '', text) # hyperlinks\n",
    "    text = re.sub(r\"\\@\\w+\", '', text) # mentions\n",
    "    text = re.sub(r\"#\", '', text) # hashtags\n",
    "    text = re.sub(r\"\\d+\\w*\", '', text) # numbers\n",
    "    text = re.sub(r\"'s\", '', text) # possesive\n",
    "    text = re.sub(r\"n't\", ' not', text) # contractions\n",
    "    \n",
    "    words = [word for word in casual_tokenize(text) if word not in stops]\n",
    "    \n",
    "    if lemmatize:\n",
    "        words = [\n",
    "            lemmatizer.lemmatize(word, tag_for_lemmatizer(tag))\n",
    "            for word, tag in pos_tag(words)\n",
    "        ]\n",
    "    else:\n",
    "        words = [\n",
    "            stemmer.stem(word)\n",
    "            for word in words\n",
    "        ]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>io app transport security mm need check if my party network pod support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mar if you have an ios device you should download our app too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>my phone do not run late io which may account for problem other day .. time be replace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>not sure how start your publication io ? we'll be live help with ask me anything session today friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two dollar tuesday be here with forklift quickkey for io suite for page for just today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>positive</td>\n",
       "      <td>ok ed let do this zlatan greizmann laporte tomorrow make happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>neutral</td>\n",
       "      <td>goal level zlatan by friday ? post every other day dsgs vine by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>neutral</td>\n",
       "      <td>would not surprise me if we enquired.he ca not be happy play fiddle zlatan but he not worth psg ask price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>neutral</td>\n",
       "      <td>rib injury for zlatan against russia be big blow if he miss austria game tuesday chance for new sunderland striker toivonen safc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>neutral</td>\n",
       "      <td>noooooo ! i be hop see zlatan be zlatan tuesday ! oh well still look forward match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5421 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  \\\n",
       "1      neutral   \n",
       "2      neutral   \n",
       "3     negative   \n",
       "4     positive   \n",
       "5      neutral   \n",
       "...        ...   \n",
       "5963  positive   \n",
       "5964   neutral   \n",
       "5965   neutral   \n",
       "5966   neutral   \n",
       "5967   neutral   \n",
       "\n",
       "                                                                                                                                 Tweet  \n",
       "1                                                              io app transport security mm need check if my party network pod support  \n",
       "2                                                                        mar if you have an ios device you should download our app too  \n",
       "3                                               my phone do not run late io which may account for problem other day .. time be replace  \n",
       "4                                not sure how start your publication io ? we'll be live help with ask me anything session today friday  \n",
       "5                                               two dollar tuesday be here with forklift quickkey for io suite for page for just today  \n",
       "...                                                                                                                                ...  \n",
       "5963                                                                   ok ed let do this zlatan greizmann laporte tomorrow make happen  \n",
       "5964                                                                   goal level zlatan by friday ? post every other day dsgs vine by  \n",
       "5965                         would not surprise me if we enquired.he ca not be happy play fiddle zlatan but he not worth psg ask price  \n",
       "5966  rib injury for zlatan against russia be big blow if he miss austria game tuesday chance for new sunderland striker toivonen safc  \n",
       "5967                                                noooooo ! i be hop see zlatan be zlatan tuesday ! oh well still look forward match  \n",
       "\n",
       "[5421 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.Tweet = tweets.Tweet.apply(preprocess)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "[('be', 890), ('i', 408), ('may', 391), ('not', 371), ('have', 353), ('for', 352), ('...', 350), ('with', 314), ('?', 294), ('you', 279), ('that', 272), ('do', 266), ('tomorrow', 238), ('but', 192), ('go', 178), ('just', 175), ('will', 164), ('he', 163), ('my', 158), ('!', 157), ('if', 150), ('get', 149), ('day', 149), ('this', 148), ('about', 132), ('say', 131), ('like', 129), ('so', 125), ('time', 115), ('me', 111), ('from', 110), ('out', 110), ('as', 107), ('make', 106), ('what', 103), ('or', 99), ('sunday', 97), ('new', 96), ('up', 92), ('one', 91), ('see', 90), ('all', 89), ('watch', 87), ('an', 85), ('we', 85), ('by', 85), ('want', 83), ('when', 83), ('think', 83), (\"i'm\", 83)]\n",
      "\n",
      "negative\n",
      "[('be', 460), ('not', 229), ('may', 213), ('i', 204), ('have', 180), ('do', 150), ('for', 138), ('that', 137), ('with', 118), ('you', 117), ('...', 115), ('?', 111), ('my', 104), ('!', 95), ('just', 95), ('but', 90), ('tomorrow', 90), ('this', 83), ('get', 81), ('he', 79), ('like', 73), ('so', 72), ('as', 70), ('go', 67), ('day', 65), ('out', 64), ('about', 64), ('say', 64), ('make', 62), ('if', 61), ('trump', 61), ('obama', 60), ('all', 58), ('no', 57), ('plan', 56), ('me', 55), ('parenthood', 53), ('think', 52), ('will', 51), ('they', 51), ('palin', 51), ('sarah', 50), ('when', 48), ('time', 46), ('now', 46), ('want', 46), ('she', 46), ('jeb', 45), ('we', 45), ('up', 44)]\n",
      "\n",
      "positive\n",
      "[('be', 1187), ('!', 707), ('i', 675), ('for', 547), ('you', 463), ('with', 451), ('tomorrow', 435), ('...', 422), ('have', 410), ('may', 400), ('my', 334), ('not', 319), ('?', 276), ('go', 274), ('that', 271), ('see', 266), ('day', 265), ('this', 257), ('get', 226), ('just', 223), ('will', 216), ('do', 216), ('but', 214), (\"i'm\", 198), ('so', 186), ('time', 183), ('all', 175), ('friday', 171), ('come', 166), ('sunday', 154), ('if', 154), ('out', 153), ('good', 153), ('watch', 152), ('new', 150), ('about', 147), ('me', 145), ('one', 144), ('make', 143), ('he', 142), ('from', 140), ('jurassic', 140), ('night', 135), ('we', 131), ('up', 129), ('like', 125), ('your', 118), ('what', 115), ('as', 115), ('can', 115)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def most_common_words(texts):\n",
    "    counter = collections.Counter()\n",
    "    for text in texts:\n",
    "        words = {word for word in casual_tokenize(text) if word not in stops}\n",
    "        counter.update(words)\n",
    "    return counter.most_common(50)\n",
    "\n",
    "for category in categories:\n",
    "    subset = tweets[tweets.Category == category].Tweet\n",
    "    print(category)\n",
    "    print(most_common_words(subset))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>neutral</td>\n",
       "      <td>baylee i've have boyfriend for every valentine day since grade hallie mine opposite ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>neutral</td>\n",
       "      <td>day after labor day be just monday that lie about be tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i'm not sure which be funny coloured-vinyl reissue mariah carey christmas album or fact that come out october</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>positive</td>\n",
       "      <td>credit phenomenal retired english teacher jan knispel from valentine for great analogy #mohreng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i know for lot people valentine day but for some just saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  \\\n",
       "5549   neutral   \n",
       "1299   neutral   \n",
       "1749   neutral   \n",
       "5437  positive   \n",
       "5528   neutral   \n",
       "\n",
       "                                                                                                              Tweet  \n",
       "5549                         baylee i've have boyfriend for every valentine day since grade hallie mine opposite ..  \n",
       "1299                                                   day after labor day be just monday that lie about be tuesday  \n",
       "1749  i'm not sure which be funny coloured-vinyl reissue mariah carey christmas album or fact that come out october  \n",
       "5437                credit phenomenal retired english teacher jan knispel from valentine for great analogy #mohreng  \n",
       "5528                                                 i know for lot people valentine day but for some just saturday  "
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def resample(train):\n",
    "#     n = 500\n",
    "#     return pandas.concat([\n",
    "#         train[train.Category == category].sample(n, replace=False)\n",
    "#         for category in categories\n",
    "#     ])\n",
    "\n",
    "def train_model(train, **kwargs):\n",
    "    vectorizer = TfidfVectorizer(binary=False, stop_words=stops, ngram_range=(1, 3))\n",
    "    classifier = LinearSVC(class_weight='balanced', **kwargs)\n",
    "    \n",
    "    train_bow = vectorizer.fit_transform(train.Tweet)\n",
    "    classifier.fit(train_bow, train.Category)\n",
    "    \n",
    "    return vectorizer, classifier\n",
    "\n",
    "def accuracy(train, test, **kwargs):\n",
    "    vectorizer, classifier = train_model(train, **kwargs)\n",
    "    \n",
    "    test_bow = vectorizer.transform(test.Tweet)\n",
    "    predictions = classifier.predict(test_bow)\n",
    "    hits = (predictions == test.Category).sum()\n",
    "    total = test.shape[0]\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01, acc=0.5206080255617336\n",
      "0.02, acc=0.554269271751949\n",
      "0.05, acc=0.5717186684204584\n",
      "0.1, acc=0.5767035935808987\n",
      "0.2, acc=0.5800167447964578\n",
      "0.5, acc=0.5838875012572424\n",
      "1, acc=0.5777356340824322\n",
      "2, acc=0.5791851231844538\n",
      "5, acc=0.576581498797921\n",
      "10, acc=0.5760463644296849\n",
      "c*=0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cv_folds = 5\n",
    "batches = np.random.randint(0, cv_folds, len(tweets))\n",
    "\n",
    "best_c = None\n",
    "best_accuracy = 0\n",
    "for c in [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]:\n",
    "    accuracies = []\n",
    "    for i in range(cv_folds):\n",
    "        train_idx = batches != i\n",
    "        test_idx = batches == i\n",
    "        acc = accuracy(tweets[train_idx], tweets[test_idx], C=c) # solver='newton-cg', multi_class='multinomial'\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    mean = np.mean(accuracies)\n",
    "    print(f\"{c}, acc={mean}\")\n",
    "    if mean > best_accuracy:\n",
    "        best_c = c\n",
    "        best_accuracy = mean\n",
    "\n",
    "print(f\"c*={best_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5, acc=0.5838875012572424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, classifier = train_model(tweets, C=best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = pandas.read_csv('data/test.csv', dtype={'Id': str, 'Tweet': str})\n",
    "test_tweets.Tweet = test_tweets.Tweet.apply(preprocess)\n",
    "test_bow = vectorizer.transform(test_tweets.Tweet)\n",
    "test_tweets['Category'] = classifier.predict(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    0.50975\n",
      "neutral     0.39175\n",
      "negative    0.09850\n",
      "Name: Category, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>trynna go ihop but all my friend be asleep so i may just go by myself whenindoubtpancakeitout</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>ihop wit bubba jay tomorrow he good eat too</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>emt krakatoa ]: so when high point your saturday be chorizo omelette ihop for late dinn ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>who down go ihop with me tomorrow morning ?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>me either ... but we get off early friday so some coworkers go ihop ... rest be history</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>definitely go ihop tomorrow</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>get pay next friday so i get buy koko i some food from ihop after game</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>dude i swear friday i be go go take you ihop but danny have go home cu he be pain</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>if i didnt have work tomorrow i really would man bring your family ihop tomorrow morning illserve you</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>i'm go ihop tomorrow</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>not available</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>perfect ! wednesday i'm do i'll be wait can we go ihop one day ?</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>will somebody please get ihop or rainbow tomorrow with me</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>i want go ihop or friday</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>anybody with steak shake or ihop move tomorrow ? ?</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>i be assemble an epic pancake posse for an ihop run thursday you do not even know how excited i be .   ... well you might know now</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>do you work ihop tomorrow</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>aug rescue return from tresco io lift casualty with minor injury rch treliske</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>not available</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>io app transport security mm need check if my party network pod support</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   Tweet  \\\n",
       "3980                                       trynna go ihop but all my friend be asleep so i may just go by myself whenindoubtpancakeitout   \n",
       "3981                                                                                         ihop wit bubba jay tomorrow he good eat too   \n",
       "3982                                         emt krakatoa ]: so when high point your saturday be chorizo omelette ihop for late dinn ...   \n",
       "3983                                                                                         who down go ihop with me tomorrow morning ?   \n",
       "3984                                             me either ... but we get off early friday so some coworkers go ihop ... rest be history   \n",
       "3985                                                                                                         definitely go ihop tomorrow   \n",
       "3986                                                              get pay next friday so i get buy koko i some food from ihop after game   \n",
       "3987                                                   dude i swear friday i be go go take you ihop but danny have go home cu he be pain   \n",
       "3988                               if i didnt have work tomorrow i really would man bring your family ihop tomorrow morning illserve you   \n",
       "3989                                                                                                                i'm go ihop tomorrow   \n",
       "3990                                                                                                                       not available   \n",
       "3991                                                                    perfect ! wednesday i'm do i'll be wait can we go ihop one day ?   \n",
       "3992                                                                           will somebody please get ihop or rainbow tomorrow with me   \n",
       "3993                                                                                                            i want go ihop or friday   \n",
       "3994                                                                                  anybody with steak shake or ihop move tomorrow ? ?   \n",
       "3995  i be assemble an epic pancake posse for an ihop run thursday you do not even know how excited i be .   ... well you might know now   \n",
       "3996                                                                                                           do you work ihop tomorrow   \n",
       "3997                                                       aug rescue return from tresco io lift casualty with minor injury rch treliske   \n",
       "3998                                                                                                                       not available   \n",
       "3999                                                             io app transport security mm need check if my party network pod support   \n",
       "\n",
       "      Category  \n",
       "3980  positive  \n",
       "3981  positive  \n",
       "3982  positive  \n",
       "3983   neutral  \n",
       "3984  positive  \n",
       "3985  positive  \n",
       "3986  positive  \n",
       "3987  positive  \n",
       "3988  positive  \n",
       "3989  positive  \n",
       "3990   neutral  \n",
       "3991  positive  \n",
       "3992   neutral  \n",
       "3993   neutral  \n",
       "3994  positive  \n",
       "3995   neutral  \n",
       "3996  positive  \n",
       "3997   neutral  \n",
       "3998   neutral  \n",
       "3999   neutral  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_tweets.Category.value_counts(normalize=True))\n",
    "\n",
    "test_tweets[['Tweet', 'Category']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.50975\n",
       "neutral     0.39175\n",
       "negative    0.09850\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.Category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 101392 features per sample; expecting 123915",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-febec3cc0ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I loved it!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I don't know what to say\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"What a fucking piece of shit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m{\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-febec3cc0ea8>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I loved it!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I don't know what to say\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"What a fucking piece of shit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m{\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-febec3cc0ea8>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_bow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/iti2/emd/lab2/.venv/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/iti2/emd/lab2/.venv/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 273\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 101392 features per sample; expecting 123915"
     ]
    }
   ],
   "source": [
    "def classify(text):\n",
    "    text = preprocess(text)\n",
    "    test_bow = vectorizer.transform([text])\n",
    "    predictions = classifier.predict(test_bow)\n",
    "    return predictions[0]\n",
    "\n",
    "phrases = [\"I loved it!\", \"I don't know what to say\", \"What a fucking piece of shit\"]\n",
    "{ phrase: classify(phrase) for phrase in phrases }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fuck', 2.2756533856175727)\n",
      "('parenthood', 1.8303820030786722)\n",
      "('plan parenthood', 1.6755022527605148)\n",
      "('not', 1.670608196986015)\n",
      "('monsanto', 1.6181405229143497)\n",
      "('best', -1.136194646180196)\n",
      "('seinfeld', -1.1082058924890865)\n",
      "('good', -0.968385358699419)\n",
      "('friday', -0.9614132949795304)\n",
      "('new', -0.9606476501187343)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vectorizer.get_feature_names(), classifier.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.csv', 'wt') as f:\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for i, row in test_tweets.iterrows():\n",
    "        f.write(f\"{row.Id},{row.Category}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer + neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 811144    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 811,243\n",
      "Trainable params: 811,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(4312, 3) (4312, 101392)\n",
      "Epoch 1/10\n",
      "4312/4312 [==============================] - 2s 572us/step - loss: 1.0702 - accuracy: 0.4659\n",
      "Epoch 2/10\n",
      "4312/4312 [==============================] - 2s 508us/step - loss: 1.0029 - accuracy: 0.4861\n",
      "Epoch 3/10\n",
      "4312/4312 [==============================] - 2s 509us/step - loss: 0.9121 - accuracy: 0.6076\n",
      "Epoch 4/10\n",
      "4312/4312 [==============================] - 2s 514us/step - loss: 0.7220 - accuracy: 0.7528\n",
      "Epoch 5/10\n",
      "4312/4312 [==============================] - 2s 517us/step - loss: 0.4878 - accuracy: 0.8599\n",
      "Epoch 6/10\n",
      "4312/4312 [==============================] - 2s 518us/step - loss: 0.3313 - accuracy: 0.9383\n",
      "Epoch 7/10\n",
      "4312/4312 [==============================] - 2s 524us/step - loss: 0.2410 - accuracy: 0.9650\n",
      "Epoch 8/10\n",
      "4312/4312 [==============================] - 2s 520us/step - loss: 0.1765 - accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "4312/4312 [==============================] - 2s 522us/step - loss: 0.1401 - accuracy: 0.9752\n",
      "Epoch 10/10\n",
      "4312/4312 [==============================] - 2s 558us/step - loss: 0.1200 - accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout, Bidirectional, Flatten\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def train_neural_net(df, train_idx):\n",
    "    train = df[train_idx]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(binary=False, ngram_range=(1, 3))\n",
    "    train_bow = vectorizer.fit_transform(train.Tweet)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(8, input_shape=(len(vectorizer.vocabulary_),), activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 64\n",
    "    num_epochs = 10\n",
    "    \n",
    "    y = np.column_stack([\n",
    "        1 * (train.Category == category)\n",
    "        for category in categories\n",
    "    ])\n",
    "    print(y.shape, train_bow.shape)\n",
    "    model.fit(train_bow, y, batch_size=batch_size, epochs=num_epochs)\n",
    "    return vectorizer, model\n",
    "\n",
    "train_idx = batches != 0\n",
    "test_idx = batches == 0\n",
    "\n",
    "vectorizer, nn = train_neural_net(tweets, batches != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5256988277727682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14, 143,  27],\n",
       "       [ 10, 257, 115],\n",
       "       [  5, 226, 312]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "test_bow = vectorizer.transform(tweets[test_idx].Tweet)\n",
    "predictions = categories[nn.predict_classes(test_bow)]\n",
    "\n",
    "print(accuracy_score(tweets[test_idx].Category, predictions))\n",
    "\n",
    "confusion_matrix(tweets[test_idx].Category, predictions)\n",
    "\n",
    "# hits = (predictions == ).sum()\n",
    "# total = tweets[test_idx].shape[0]\n",
    "# hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 8)                 992104    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 992,203\n",
      "Trainable params: 992,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(5421, 3) (5421, 124012)\n",
      "Epoch 1/10\n",
      "5421/5421 [==============================] - 4s 651us/step - loss: 1.0638 - accuracy: 0.4778\n",
      "Epoch 2/10\n",
      "5421/5421 [==============================] - 4s 675us/step - loss: 0.9722 - accuracy: 0.4822\n",
      "Epoch 3/10\n",
      "5421/5421 [==============================] - 4s 650us/step - loss: 0.7979 - accuracy: 0.6455\n",
      "Epoch 4/10\n",
      "5421/5421 [==============================] - 4s 662us/step - loss: 0.5824 - accuracy: 0.7877\n",
      "Epoch 5/10\n",
      "5421/5421 [==============================] - 3s 602us/step - loss: 0.4278 - accuracy: 0.8211\n",
      "Epoch 6/10\n",
      "5421/5421 [==============================] - 3s 563us/step - loss: 0.3266 - accuracy: 0.8552\n",
      "Epoch 7/10\n",
      "5421/5421 [==============================] - 3s 620us/step - loss: 0.2510 - accuracy: 0.9157\n",
      "Epoch 8/10\n",
      "5421/5421 [==============================] - 4s 808us/step - loss: 0.1904 - accuracy: 0.9349\n",
      "Epoch 9/10\n",
      "5421/5421 [==============================] - 4s 667us/step - loss: 0.1623 - accuracy: 0.9332\n",
      "Epoch 10/10\n",
      "5421/5421 [==============================] - 3s 606us/step - loss: 0.1383 - accuracy: 0.9364\n"
     ]
    }
   ],
   "source": [
    "vectorizer, nn = train_neural_net(tweets)\n",
    "test_bow = vectorizer.transform(test_tweets.Tweet)\n",
    "test_tweets['Category'] = categories[nn.predict_classes(test_bow)]\n",
    "\n",
    "with open('predictions.csv', 'wt') as f:\n",
    "    f.write(\"Id,Category\\n\")\n",
    "    for i, row in test_tweets.iterrows():\n",
    "        f.write(f\"{row.Id},{row.Category}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'char_level',\n",
       " 'document_count',\n",
       " 'filters',\n",
       " 'fit_on_sequences',\n",
       " 'fit_on_texts',\n",
       " 'get_config',\n",
       " 'index_docs',\n",
       " 'index_word',\n",
       " 'lower',\n",
       " 'num_words',\n",
       " 'oov_token',\n",
       " 'sequences_to_matrix',\n",
       " 'sequences_to_texts',\n",
       " 'sequences_to_texts_generator',\n",
       " 'split',\n",
       " 'texts_to_matrix',\n",
       " 'texts_to_sequences',\n",
       " 'texts_to_sequences_generator',\n",
       " 'to_json',\n",
       " 'word_counts',\n",
       " 'word_docs',\n",
       " 'word_index']"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweets.Tweet)\n",
    "\n",
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(tweets.Tweet)\n",
    "\n",
    "max_words = max(len(sequence) for sequence in sequences)\n",
    "sequences = sequence.pad_sequences(sequences, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 32, 128)           1182976   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,274,879\n",
      "Trainable params: 1,274,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_size = 128\n",
    "\n",
    "# model = Sequential([\n",
    "#     Embedding(vocab_size, 128, input_shape=(max_words,)),\n",
    "#     LSTM(64),\n",
    "#     Dense(16, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(16, activation='relu'),\n",
    "#     Dense(3, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_1h = np.column_stack([\n",
    "    1 * (tweets.Category == category)\n",
    "    for category in categories\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, categories_1h)\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.index_word[idx] for idx in x_train[0,:] if idx > 0]\n",
    "categories[y_test.argmax(1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikolaj/Code/iti2/emd/lab2/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.9753 - accuracy: 0.4982\n",
      "Epoch 2/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.7771 - accuracy: 0.6416\n",
      "Epoch 3/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.5729 - accuracy: 0.7661\n",
      "Epoch 4/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.3704 - accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.2332 - accuracy: 0.9154\n",
      "Epoch 6/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.1501 - accuracy: 0.9461\n",
      "Epoch 7/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.1077 - accuracy: 0.9629\n",
      "Epoch 8/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.0867 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.0734 - accuracy: 0.9759\n",
      "Epoch 10/10\n",
      "4065/4065 [==============================] - 5s 1ms/step - loss: 0.0572 - accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16c723c18>"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.551622418879056"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categories[]\n",
    "predictions = model.predict_classes(x_test)\n",
    "true_labels = y_test.argmax(1)\n",
    "\n",
    "accuracy_score(true_labels, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
